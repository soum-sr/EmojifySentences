{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:28.409505Z",
     "start_time": "2020-05-22T09:33:28.404500Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import emoji\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, Activation, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:16.107439Z",
     "start_time": "2020-05-22T09:33:16.090436Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:24.819761Z",
     "start_time": "2020-05-22T09:33:16.110433Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:24.841735Z",
     "start_time": "2020-05-22T09:33:24.821730Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_emoji.csv', header=None, usecols=[0,1])\n",
    "dataset= np.array(df)\n",
    "phrase, emoji = list(), list()\n",
    "for p, e in dataset:\n",
    "    phrase.append(p)\n",
    "    emoji.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:24.949915Z",
     "start_time": "2020-05-22T09:33:24.845741Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    phrase , emoji = list(), list()\n",
    "    df = pd.read_csv(filename, header=None, usecols=[0,1])\n",
    "    dataset= np.array(df)\n",
    "    phrase, emoji = list(), list()\n",
    "    for p, e in dataset:\n",
    "        if '\\t' in p:\n",
    "            p = p[:-1]\n",
    "        phrase.append(p)\n",
    "        emoji.append(e)\n",
    "    X = np.array(phrase)\n",
    "    y = np.array(emoji, dtype=int)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:25.070901Z",
     "start_time": "2020-05-22T09:33:24.952892Z"
    }
   },
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:25.194949Z",
     "start_time": "2020-05-22T09:33:25.072897Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_to_emoji(val):\n",
    "    return emoji.emojize(emoji_dictionary[str(val)], use_aliases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:25.332757Z",
     "start_time": "2020-05-22T09:33:25.196969Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('train_emoji.csv')\n",
    "X_test, Y_test = read_csv('tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:25.464705Z",
     "start_time": "2020-05-22T09:33:25.335711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=len).split())\n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:31.035314Z",
     "start_time": "2020-05-22T09:33:31.029309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÑ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(X_train[idx] , label_to_emoji(Y_train[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:32.180319Z",
     "start_time": "2020-05-22T09:33:32.172323Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i,j] = word_to_index[w]\n",
    "            j+=1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:33.546252Z",
     "start_time": "2020-05-22T09:33:33.541255Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:34.083396Z",
     "start_time": "2020-05-22T09:33:34.077403Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "\n",
    "    embedding_layer.build((None,)) \n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:34.402136Z",
     "start_time": "2020-05-22T09:33:34.396134Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings = embedding_layer(sentence_indices)\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(units=5, activation='softmax')(X)\n",
    "    X = Activation('softmax')(X)\n",
    "\n",
    "    model = Model(sentence_indices,X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:36.646499Z",
     "start_time": "2020-05-22T09:33:34.997642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:38.413811Z",
     "start_time": "2020-05-22T09:33:38.356578Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:33:38.660403Z",
     "start_time": "2020-05-22T09:33:38.654398Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:34:20.067128Z",
     "start_time": "2020-05-22T09:33:45.828343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188 samples\n",
      "Epoch 1/60\n",
      "188/188 [==============================] - 4s 21ms/sample - loss: 1.5932 - accuracy: 0.2660\n",
      "Epoch 2/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.5635 - accuracy: 0.2926\n",
      "Epoch 3/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 1.5503 - accuracy: 0.3511\n",
      "Epoch 4/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.5222 - accuracy: 0.3723\n",
      "Epoch 5/60\n",
      "188/188 [==============================] - 1s 4ms/sample - loss: 1.4817 - accuracy: 0.4255\n",
      "Epoch 6/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.4401 - accuracy: 0.4734\n",
      "Epoch 7/60\n",
      "188/188 [==============================] - 1s 4ms/sample - loss: 1.3877 - accuracy: 0.5160\n",
      "Epoch 8/60\n",
      "188/188 [==============================] - 1s 5ms/sample - loss: 1.3119 - accuracy: 0.6170\n",
      "Epoch 9/60\n",
      "188/188 [==============================] - 1s 4ms/sample - loss: 1.2318 - accuracy: 0.6915\n",
      "Epoch 10/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.1856 - accuracy: 0.7287\n",
      "Epoch 11/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 1.1677 - accuracy: 0.7447\n",
      "Epoch 12/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.1304 - accuracy: 0.7926\n",
      "Epoch 13/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 1.1428 - accuracy: 0.7660\n",
      "Epoch 14/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0962 - accuracy: 0.8085\n",
      "Epoch 15/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0878 - accuracy: 0.8085\n",
      "Epoch 16/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0640 - accuracy: 0.8617\n",
      "Epoch 17/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0325 - accuracy: 0.8723\n",
      "Epoch 18/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0255 - accuracy: 0.8936\n",
      "Epoch 19/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 1.0430 - accuracy: 0.8670\n",
      "Epoch 20/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 1.0232 - accuracy: 0.8777\n",
      "Epoch 21/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 1.0786 - accuracy: 0.8351\n",
      "Epoch 22/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 1.0096 - accuracy: 0.8989\n",
      "Epoch 23/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9995 - accuracy: 0.9043\n",
      "Epoch 24/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9750 - accuracy: 0.9362\n",
      "Epoch 25/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9861 - accuracy: 0.9202\n",
      "Epoch 26/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9849 - accuracy: 0.9255\n",
      "Epoch 27/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9631 - accuracy: 0.9415\n",
      "Epoch 28/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9483 - accuracy: 0.9574\n",
      "Epoch 29/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9553 - accuracy: 0.9521\n",
      "Epoch 30/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9540 - accuracy: 0.9574\n",
      "Epoch 31/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9451 - accuracy: 0.9628\n",
      "Epoch 32/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9462 - accuracy: 0.9574\n",
      "Epoch 33/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9907 - accuracy: 0.9096\n",
      "Epoch 34/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9410 - accuracy: 0.9628\n",
      "Epoch 35/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9374 - accuracy: 0.9734\n",
      "Epoch 36/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9324 - accuracy: 0.9734\n",
      "Epoch 37/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9423 - accuracy: 0.9628\n",
      "Epoch 38/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9691 - accuracy: 0.9309\n",
      "Epoch 39/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9645 - accuracy: 0.9362\n",
      "Epoch 40/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9562 - accuracy: 0.9468\n",
      "Epoch 41/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9425 - accuracy: 0.9628\n",
      "Epoch 42/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9379 - accuracy: 0.96810s - loss: 0.9604 - accuracy: 0.95 - ETA: 0s - loss: 0.9474 - accuracy: \n",
      "Epoch 43/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9280 - accuracy: 0.9787\n",
      "Epoch 44/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9275 - accuracy: 0.9787\n",
      "Epoch 45/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9266 - accuracy: 0.9787\n",
      "Epoch 46/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9257 - accuracy: 0.9787\n",
      "Epoch 47/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9260 - accuracy: 0.9787\n",
      "Epoch 48/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9252 - accuracy: 0.9787\n",
      "Epoch 49/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9257 - accuracy: 0.9787\n",
      "Epoch 50/60\n",
      "188/188 [==============================] - 0s 2ms/sample - loss: 0.9249 - accuracy: 0.9787\n",
      "Epoch 51/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9255 - accuracy: 0.9787\n",
      "Epoch 52/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9246 - accuracy: 0.9787\n",
      "Epoch 53/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9228 - accuracy: 0.9840\n",
      "Epoch 54/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9223 - accuracy: 0.9840\n",
      "Epoch 55/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9237 - accuracy: 0.9787\n",
      "Epoch 56/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9209 - accuracy: 0.9840\n",
      "Epoch 57/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9239 - accuracy: 0.9787\n",
      "Epoch 58/60\n",
      "188/188 [==============================] - 0s 3ms/sample - loss: 0.9212 - accuracy: 0.9840\n",
      "Epoch 59/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9212 - accuracy: 0.9840\n",
      "Epoch 60/60\n",
      "188/188 [==============================] - 1s 3ms/sample - loss: 0.9208 - accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_indices, Y_train_oh, epochs = 60, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:34:23.704946Z",
     "start_time": "2020-05-22T09:34:22.676943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/1 - 1s - loss: 0.9049 - accuracy: 1.0000\n",
      "\n",
      "Test accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh,verbose=2)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:35:00.577964Z",
     "start_time": "2020-05-22T09:35:00.411973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üç¥ prediction: I want to eatüç¥\n",
      "Expected emoji:üòû prediction: he did not answerüòû\n",
      "Expected emoji:üòÑ prediction: he got a very nice raiseüòÑ\n",
      "Expected emoji:üòÑ prediction: she got me a nice presentüòÑ\n",
      "Expected emoji:üòÑ prediction: ha ha ha it was so funnyüòÑ\n",
      "Expected emoji:üòÑ prediction: he is a good friendüòÑ\n",
      "Expected emoji:üòû prediction: I am upsetüòû\n",
      "Expected emoji:üòÑ prediction: We had such a lovely dinner tonightüòÑ\n",
      "Expected emoji:üç¥ prediction: where is the foodüç¥\n",
      "Expected emoji:üòÑ prediction: Stop making this joke ha ha haüòÑ\n",
      "Expected emoji:‚öæ prediction: where is the ball‚öæ\n",
      "Expected emoji:üòû prediction: work is hardüòû\n",
      "Expected emoji:üòû prediction: This girl is messing with meüòû\n",
      "Expected emoji:üòû prediction: are you seriousüòû\n",
      "Expected emoji:‚öæ prediction: Let us go play baseball‚öæ\n",
      "Expected emoji:üòû prediction: This stupid grader is not working üòû\n",
      "Expected emoji:üòû prediction: work is horribleüòû\n",
      "Expected emoji:üòÑ prediction: Congratulation for having a babyüòÑ\n",
      "Expected emoji:üòû prediction: stop pissing me offüòû\n",
      "Expected emoji:üç¥ prediction: any suggestions for dinnerüç¥\n",
      "Expected emoji:‚ù§Ô∏è prediction: I love taking breaks‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: you brighten my dayüòÑ\n",
      "Expected emoji:üç¥ prediction: I boiled riceüç¥\n",
      "Expected emoji:üòû prediction: she is a bullyüòû\n",
      "Expected emoji:üòû prediction: Why are you feeling badüòû\n",
      "Expected emoji:üòû prediction: I am upsetüòû\n",
      "Expected emoji:‚öæ prediction: give me the ball‚öæ\n",
      "Expected emoji:‚ù§Ô∏è prediction: My grandmother is the love of my life‚ù§Ô∏è\n",
      "Expected emoji:‚öæ prediction: enjoy your game‚öæ\n",
      "Expected emoji:üòÑ prediction: valentine day is nearüòÑ\n",
      "Expected emoji:‚ù§Ô∏è prediction: I miss you so much‚ù§Ô∏è\n",
      "Expected emoji:‚öæ prediction: throw the ball‚öæ\n",
      "Expected emoji:üòû prediction: My life is so boringüòû\n",
      "Expected emoji:üòÑ prediction: she said yesüòÑ\n",
      "Expected emoji:üòÑ prediction: will you be my valentineüòÑ\n",
      "Expected emoji:‚öæ prediction: he can pitch really well‚öæ\n",
      "Expected emoji:üòÑ prediction: dance with meüòÑ\n",
      "Expected emoji:üç¥ prediction: I am hungryüç¥\n",
      "Expected emoji:üç¥ prediction: See you at the restaurantüç¥\n",
      "Expected emoji:üòÑ prediction: I like to laughüòÑ\n",
      "Expected emoji:‚öæ prediction: I will  run‚öæ\n",
      "Expected emoji:‚ù§Ô∏è prediction: I like your jacket ‚ù§Ô∏è\n",
      "Expected emoji:‚ù§Ô∏è prediction: i miss her‚ù§Ô∏è\n",
      "Expected emoji:‚öæ prediction: what is your favorite baseball game‚öæ\n",
      "Expected emoji:üòÑ prediction: Good jobüòÑ\n",
      "Expected emoji:‚ù§Ô∏è prediction: I love you to the stars and back‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: What you did was awesomeüòÑ\n",
      "Expected emoji:üòÑ prediction: ha ha ha lolüòÑ\n",
      "Expected emoji:üòû prediction: I do not want to jokeüòû\n",
      "Expected emoji:üòû prediction: go awayüòû\n",
      "Expected emoji:üòû prediction: yesterday we lost againüòû\n",
      "Expected emoji:‚ù§Ô∏è prediction: family is all I have‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: you are failing this exerciseüòû\n",
      "Expected emoji:üòÑ prediction: Good jokeüòÑ\n",
      "Expected emoji:üòÑ prediction: You deserve this nice prizeüòÑ\n",
      "Expected emoji:üç¥ prediction: I did not have breakfast üç¥\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T09:36:03.537110Z",
     "start_time": "2020-05-22T09:36:03.436115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am good man üòÑ\n"
     ]
    }
   ],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_test = np.array(['I am good man'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
